{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Neural Network\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "sns.set_theme(style='darkgrid', palette='hls')\n",
    "\n",
    "import torch \n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn \n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Custom(Dataset):\n",
    "    def __init__(self, X_data, Y_data):\n",
    "        X_data = X_data\n",
    "        Y_data = Y_data\n",
    "        self.x, self.y = self.clean(X_data, Y_data)\n",
    "        self.samples = self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples\n",
    "\n",
    "    def clean(self,X_data,Y_data):\n",
    "        x = torch.from_numpy(X_data).float()\n",
    "        y = torch.from_numpy(Y_data.values).float()\n",
    "        y = y[:,None]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../Corpus/resampled_data/X_train_resampled_genero.csv', index_col=0)\n",
    "y_train = pd.read_csv('../Corpus/resampled_data/y_train_resampled_genero.csv', index_col=0)\n",
    "\n",
    "dataset_train = Dataset_Custom(X_train, y_train)\n",
    "dataset_test = Dataset_Custom(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 30\n",
    "\n",
    "trainloader = DataLoader(dataset=dataset_train, batch_size=batch, shuffle=True)\n",
    "testloader = DataLoader(dataset=dataset_test, batch_size=batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_size, hidden_sizes, output_size, activation_functions):\n",
    "    layers = []\n",
    "    layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "    \n",
    "    # Add hidden layers\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        layers.append(('fc{}'.format(i), nn.Linear(layer_sizes[i-1], layer_sizes[i])))\n",
    "        if activation_functions[i-1] == 'relu':\n",
    "            layers.append(('relu{}'.format(i), nn.ReLU()))\n",
    "        elif activation_functions[i-1] == 'sigmoid':\n",
    "            layers.append(('sigmoid{}'.format(i), nn.Sigmoid()))\n",
    "\n",
    "    model = nn.Sequential(OrderedDict(layers))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of loss, learning rate & epochs\n",
    "def train_rna(model):\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    epochs = 100\n",
    "    print_every = int((X_train.shape[0]/batch) / 20)\n",
    "    steps = 0 \n",
    "    list_loss = []\n",
    "    list_loss_test = []\n",
    "    list_epochs = []\n",
    "\n",
    "    # Comenzando entrenamiento. . . \n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        # En cada epoca cargamos todos los batches \n",
    "        for inputs, labels in iter(trainloader):\n",
    "            steps += 1\n",
    "            # Reiniciar los gradientes\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model.forward(inputs)\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backprogation\n",
    "            loss.backward()\n",
    "            # Actualiza los pesos de acuerdo a un paso del optimizador\n",
    "            optimizer.step()\n",
    "            # Guardamos la perdida para control del entrenamiento\n",
    "            running_loss += loss.item()\n",
    "            # imprimimos cada 20% lotes\n",
    "            if steps % print_every == 0:\n",
    "                list_loss.append(running_loss/print_every)\n",
    "                running_loss = 0\n",
    "                \n",
    "                output_test = model.forward(dataset_test.x)\n",
    "                loss_t = criterion(output_test, dataset_test.y)\n",
    "                list_loss_test.append(loss_t.item())\n",
    "                list_epochs.append(e+1)\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df['epochs'] = list_epochs\n",
    "    df['loss_train'] = list_loss\n",
    "    df['loss_test'] = list_loss_test\n",
    "\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "    sns.lineplot(x=\"epochs\", y=\"loss_train\", data=df, color='yellow', label='Entrenamiento')\n",
    "    sns.lineplot(x=\"epochs\", y=\"loss_test\", data=df, color='violet', label='Prueba')\n",
    "\n",
    "    output_acc = model.forward(dataset_test.x)\n",
    "\n",
    "    # Medidas\n",
    "    pred = torch.unsqueeze(torch.tensor([ 0 if p<=0.5 else 1 for p in output_acc]),1)\n",
    "    label = dataset_test.y\n",
    "    pred = pred.numpy()\n",
    "    label = label.numpy()\n",
    "\n",
    "    # Calcular la exactitud\n",
    "    exactitud = round(accuracy_score(label, pred),2)\n",
    "    #print(\"Exactitud:\", exactitud)\n",
    "\n",
    "    # Calcular la preci sión\n",
    "    precision = round(precision_score(label, pred),2)\n",
    "    #print(\"Precisión:\", precision)\n",
    "\n",
    "    # Calcular la puntuación F1\n",
    "    f1 = round(f1_score(label, pred),2)\n",
    "    #print(\"Puntuación F1:\", f1)\n",
    "    recall = round(recall_score(label, pred),2)\n",
    "\n",
    "    print(\"Exactitud (Accuracy):\", exactitud)\n",
    "    print(\"Precisión (Precision):\", precision)\n",
    "    print(\"F1-score:\", f1)\n",
    "    print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = build_model(X.shape[1], [22], 1, ['relu','sigmoid'])\n",
    "train_rna(modelo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
